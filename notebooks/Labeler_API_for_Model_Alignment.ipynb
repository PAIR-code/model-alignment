{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el1M5JU6Kl2y"
      },
      "source": [
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "# Labeler API\n",
        "\n",
        "This notebook shows how the Model Alignment python API can be used to create labeling prompts with user feedback.\n",
        "\n",
        "Prompts are comprised of constitutional principles which are evolved given training data.\n",
        "\n",
        "This notebook creates a classifier for offensive text based on the [ETHOS](https://arxiv.org/abs/2006.08328) dataset using a Gemini model. It requires the user to provide an [API key](https://aistudio.google.com/app/apikey)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX6haaEhKnZ0"
      },
      "source": [
        "# Installation and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twddj_yNdKup"
      },
      "outputs": [],
      "source": [
        "!pip install model-alignment\n",
        "from model_alignment import model_helper\n",
        "from model_alignment import labeler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnW8kztxy-0U"
      },
      "outputs": [],
      "source": [
        "# @title Config\n",
        "# Provide a Gemini API key for model calls\n",
        "api_key = '' # @param {type:\"string\"}\n",
        "train_model_name = 'gemini-pro' # @param {type:\"string\"}\n",
        "eval_model_name = 'gemini-pro' # @param {type:\"string\"}\n",
        "\n",
        "NUM_TRAIN_EXAMPLES = 100 #@param\n",
        "\n",
        "LABEL = 'isHate' #@param  {type:\"string\"}\n",
        "TASK_DESCRIPTION = 'Does the example contain offensive text?' #@param {type: \"string\"}\n",
        "INPUTS = ['comment'] #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-HXVxw4av4c"
      },
      "outputs": [],
      "source": [
        "# @title Download ETHOS dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset/master/ethos/ethos_data/Ethos_Dataset_Binary.csv'\n",
        "df = pd.read_csv(url, delimiter=';')\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PW4ZPiESbOf6"
      },
      "outputs": [],
      "source": [
        "# Binarize data\n",
        "df['isHate'] = df['isHate'] \u003e 0.5\n",
        "\n",
        "# Split into train / test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.05, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqC3o3nqcQMy"
      },
      "outputs": [],
      "source": [
        "# Display training set info\n",
        "train_df['isHate'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCMtt0mhcSPe"
      },
      "outputs": [],
      "source": [
        "# Display test set info\n",
        "test_df['isHate'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmSkORV4qfw7"
      },
      "outputs": [],
      "source": [
        "# Sample training examples if specified.\n",
        "if NUM_TRAIN_EXAMPLES is not None:\n",
        "  train_df = train_df.sample(\n",
        "    min(NUM_TRAIN_EXAMPLES, train_df.shape[0])\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAwLCts0yVL9"
      },
      "outputs": [],
      "source": [
        "# Create the labeler object to train a constitutional labeling prompt.\n",
        "labeler_maker = labeler.Labeler(input_names=INPUTS,\n",
        "                       label_name=LABEL,\n",
        "                       label_values = train_df[LABEL].unique(),\n",
        "                       task_description=TASK_DESCRIPTION,\n",
        "                       train_model_helper=model_helper.GeminiModelHelper(api_key, model_name=train_model_name),\n",
        "                       eval_model_helper=model_helper.GeminiModelHelper(api_key, model_name=eval_model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rVg9jafyXeg"
      },
      "outputs": [],
      "source": [
        "# Initialize the labeler, which will create an initial set of simple principles.\n",
        "toxicity_labeler = labeler_maker.initialize_checkpoint(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhHHl41lq62c"
      },
      "outputs": [],
      "source": [
        "# Print out the current labeler info.\n",
        "labeler.print_checkpoint(toxicity_labeler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKQhPXDaLqaS"
      },
      "source": [
        "## Test out labeler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ic-eOf0BKhv_"
      },
      "outputs": [],
      "source": [
        "# Test the newly-initialized labeler on the test dataset.\n",
        "predictions = labeler_maker.infer_checkpoint(toxicity_labeler, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yQPLlmhpHHB"
      },
      "outputs": [],
      "source": [
        "# Print some results\n",
        "for i in range(3):\n",
        "  print(\"Request:\")\n",
        "  print(predictions[i]['request'])\n",
        "  print(\"Response:\")\n",
        "  print(predictions[i]['prediction'])\n",
        "  print(\"================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_CxHVmJmpUM"
      },
      "outputs": [],
      "source": [
        "# Print the scorecard for the current labeler,.\n",
        "scorecard = labeler_maker.get_scorecard(\n",
        "    test_df, predictions\n",
        ")\n",
        "\n",
        "print(f\"Accuracy: {round(scorecard['accuracy'], 2)}\")\n",
        "print(f\"Fscore: {scorecard['fscore']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGmHG2KuejmS"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xy5FFH8zAx1"
      },
      "outputs": [],
      "source": [
        "# Set the number of training steps to run.\n",
        "NUM_TRAIN_STEPS = 3 # @param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ybVJ-g4zFQf"
      },
      "outputs": [],
      "source": [
        "# Run the training loop to train the labeler prompt, printing the labeler scorecard after each training step.\n",
        "for i in range(NUM_TRAIN_STEPS):\n",
        "  print(f\"======== Iteration {i} ==========\")\n",
        "  toxicity_labeler = labeler_maker.train_step(toxicity_labeler, train_df)\n",
        "  predictions = labeler_maker.infer_checkpoint(toxicity_labeler, test_df)\n",
        "  scorecard = labeler_maker.get_scorecard(test_df, predictions)\n",
        "  print(f\"Accuracy: {round(scorecard['accuracy'], 2)}\")\n",
        "  print(f\"Fscore: {scorecard['fscore']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtwi9lBEUQ1Q"
      },
      "source": [
        "## Try out labeler on a new example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wWagcy72u-r"
      },
      "outputs": [],
      "source": [
        "# Define a data frame with new examples to run the labeler on.\n",
        "new_examples = pd.DataFrame({'comment': ['I hate all people', 'I love my sister']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1dabVwf1Jky"
      },
      "outputs": [],
      "source": [
        "# Run the labeler on those new examples.\n",
        "predictions = labeler_maker.infer_checkpoint(toxicity_labeler, new_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzRSI8zM2K-9"
      },
      "outputs": [],
      "source": [
        "# Print out the results of the labeling.\n",
        "for index, item in enumerate(zip(new_examples.iterrows(), predictions)):\n",
        "  i, example = item[0]\n",
        "  print(f\"==========\\n\\033[1mExample {index}\\033[0m\\n==========\")\n",
        "  features = example[INPUTS].to_dict()\n",
        "  for feature in INPUTS:\n",
        "    print(f'{feature}: {features[feature]}')\n",
        "  print(\"\\033[1m\\033[31mPrediction:\\033[0m\", item[1]['prediction'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
